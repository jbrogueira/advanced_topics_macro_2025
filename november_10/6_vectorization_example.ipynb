{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d7072f",
   "metadata": {},
   "source": [
    "# Inventory Management Model: Vectorization Practice\n",
    "\n",
    "**Prepared for the Bank of Portugal Computational Economics Course (Oct 2025)**\n",
    "\n",
    "**Author:** [John Stachurski](https://johnstachurski.net)\n",
    "\n",
    "This notebook demonstrates a stochastic dynamic inventory management model and compares different computational approaches for calculating transition probabilities.\n",
    "\n",
    "## Problem Overview\n",
    "\n",
    "We have an inventory system with:\n",
    "\n",
    "- $K$: Maximum inventory capacity\n",
    "- $p$: Parameter for demand shock distribution\n",
    "\n",
    "Inventory evolves according to \n",
    "\n",
    "$$\n",
    "    X_{t+1} = \\max(X_t - D_{t+1}, 0) + A_t\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- $X_t$ is current inventory (number of units),\n",
    "- $D_{t+1}$ is an IID demand shock, and\n",
    "- $A_t$ is the current order (number of units).\n",
    "\n",
    "We are interested in computing the transition probability kernel\n",
    "\n",
    "$$P(x, a, y) := \\mathbb P\\{X_{t+1}=y \\,|\\, X_t = x, A_t = a \\}$$\n",
    "\n",
    "More explicitly,\n",
    "\n",
    "$$P(x, a, y) = \\sum_{d \\geq 0} \\mathbb{1}\\{\\max(x - d, 0) + a = y\\} \\phi(d)$$\n",
    "\n",
    "Here\n",
    "\n",
    "- $d$ is the demand shock\n",
    "- $\\phi$ is the probability density function for demand\n",
    "\n",
    "\n",
    "## Mathematical Derivation\n",
    "\n",
    "The transition probability kernel obeys\n",
    "\n",
    "\\begin{align}\n",
    "P(x, a, y) &= \\sum_{d \\geq 0} \\mathbb{1}\\{\\max(x - d, 0) + a = y\\} \\phi(d) \\\\\n",
    "&= \\sum_{d < x} \\mathbb{1}\\{x - d + a = y\\} \\phi(d) + \\sum_{d \\geq x} \\mathbb{1}\\{a = y\\} \\phi(d) \\\\\n",
    "&= \\sum_{d < x} \\mathbb{1}\\{d = x + a - y\\} \\phi(d) + \\mathbb{1}\\{y = a\\} F(x) \\\\\n",
    "&= \\mathbb{1}\\{0 \\leq x + a - y < x\\} \\phi(x + a - y) + \\mathbb{1}\\{y = a\\} F(x)\n",
    "\\end{align}\n",
    "\n",
    "Where $F(x) = P\\{D \\geq x\\}$ is the survival function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74f2d5",
   "metadata": {},
   "source": [
    "## Implementation Approaches\n",
    "\n",
    "We'll compare three different computational approaches:\n",
    "1. **Loop-based** (Numba JIT compiled)\n",
    "2. **Vectorized** (JAX vectorized operations)\n",
    "3. **Vmap** (JAX's functional transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f639827f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T05:07:24.731318Z",
     "iopub.status.busy": "2025-10-07T05:07:24.730746Z",
     "iopub.status.idle": "2025-10-07T05:07:25.255127Z",
     "shell.execute_reply": "2025-10-07T05:07:25.254661Z"
    }
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import NamedTuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "391b175a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T05:07:25.256461Z",
     "iopub.status.busy": "2025-10-07T05:07:25.256261Z",
     "iopub.status.idle": "2025-10-07T05:07:25.259242Z",
     "shell.execute_reply": "2025-10-07T05:07:25.258859Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(NamedTuple):\n",
    "    K: int = 50     # max inventory\n",
    "    p: float = 0.6  # demand shock parameter\n",
    "\n",
    "\n",
    "def ϕ(p, d):\n",
    "    \"\"\"PDF for demand shock: ϕ(d) = (1-p)^d * p\"\"\"\n",
    "    return (1 - p)**d * p\n",
    "\n",
    "\n",
    "def F(p, x):\n",
    "    \"\"\"Survival function: F(x) = P{D ≥ x} = (1-p)^x\"\"\"\n",
    "    return (1 - p)**x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdda50ca",
   "metadata": {},
   "source": [
    "Let's create a model instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dce9b700",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T05:07:25.260536Z",
     "iopub.status.busy": "2025-10-07T05:07:25.260385Z",
     "iopub.status.idle": "2025-10-07T05:07:25.263009Z",
     "shell.execute_reply": "2025-10-07T05:07:25.262538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Model(K=50, p=0.6)\n",
      "Demand PDF: ϕ(d) = (1-p)^d * p = (1-0.6)^d * 0.6\n",
      "Survival function: F(x) = (1-p)^x = (1-0.6)^x\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "print(f\"Created {model}\")\n",
    "print(f\"Demand PDF: ϕ(d) = (1-p)^d * p = (1-{model.p})^d * {model.p}\")\n",
    "print(f\"Survival function: F(x) = (1-p)^x = (1-{model.p})^x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80977a1",
   "metadata": {},
   "source": [
    "## Method 1: Loop-based Implementation (Numba)\n",
    "\n",
    "This approach uses traditional nested loops with Numba JIT compilation for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2edf8d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T05:07:25.264327Z",
     "iopub.status.busy": "2025-10-07T05:07:25.264181Z",
     "iopub.status.idle": "2025-10-07T05:07:25.268751Z",
     "shell.execute_reply": "2025-10-07T05:07:25.268518Z"
    }
   },
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def generate_kernel_loops(model):\n",
    "    \"\"\"\n",
    "    Loop-based computation of the transition probability kernel P(x, a, y).\n",
    "    See the mathematical derivation above for the complete formula.\n",
    "    \"\"\"\n",
    "    K, p = model\n",
    "    S = K + 1\n",
    "    P = np.zeros((S, S, S))\n",
    "\n",
    "    def ϕ(d):\n",
    "        return (1 - p)**d * p\n",
    "\n",
    "    def F(x):\n",
    "        return (1 - p)**x\n",
    "\n",
    "    for x in range(S):\n",
    "        for a in range(S):\n",
    "            for y in range(S):\n",
    "                # implement 1{0 ≤ x + a - y < x} φ(x + a - y) + 1{y = a} F(x)\n",
    "                phi_value = (0 <= x + a - y < x) * ϕ(x + a - y) \n",
    "                f_value = (y == a) * F(x)\n",
    "                P[x, a, y] = phi_value + f_value\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4429f51a",
   "metadata": {},
   "source": [
    "## Method 2: Vectorized Implementation (JAX)\n",
    "\n",
    "This approach uses JAX's vectorized operations to compute all probabilities simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6633699d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T05:07:25.270069Z",
     "iopub.status.busy": "2025-10-07T05:07:25.269925Z",
     "iopub.status.idle": "2025-10-07T05:07:25.272908Z",
     "shell.execute_reply": "2025-10-07T05:07:25.272503Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_kernel_vectorized(model):\n",
    "    \"\"\"\n",
    "    Fully vectorized JAX-based computation of the transition probability kernel P(x, a, y).\n",
    "    See the mathematical derivation above for the complete formula.\n",
    "    \"\"\"\n",
    "    K, p = model\n",
    "    S = K + 1\n",
    "    \n",
    "    # Create meshgrids for vectorized computation\n",
    "    x_grid, a_grid, y_grid = jnp.meshgrid(\n",
    "        jnp.arange(S), jnp.arange(S), jnp.arange(S), indexing='ij'\n",
    "    )\n",
    "    \n",
    "    # Initialize probability tensor\n",
    "    P = jnp.zeros((S, S, S))\n",
    "    \n",
    "    # Vectorized computation of the first term: 1{0 ≤ x + a - y < x} φ(x + a - y)\n",
    "    d_candidate = x_grid + a_grid - y_grid\n",
    "    valid_d = jnp.logical_and(d_candidate >= 0, d_candidate < x_grid) \n",
    "    phi_values = valid_d * ϕ(p, d_candidate)\n",
    "    \n",
    "    # Second term: I{y = a} F(x)\n",
    "    y_eq_a = jnp.equal(y_grid, a_grid)\n",
    "    f_values = y_eq_a * F(p, x_grid) \n",
    "  \n",
    "    # Combine both terms\n",
    "    P = phi_values + f_values\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3654fc",
   "metadata": {},
   "source": [
    "## Method 3: Vmap Implementation (JAX)\n",
    "\n",
    "This approach uses JAX's `vmap` (vectorized map) to transform a scalar function into a vectorized one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a571ff5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T05:07:25.274138Z",
     "iopub.status.busy": "2025-10-07T05:07:25.273921Z",
     "iopub.status.idle": "2025-10-07T05:07:25.277078Z",
     "shell.execute_reply": "2025-10-07T05:07:25.276677Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_kernel_vmap(model): \n",
    "    \"\"\"\n",
    "    Vmap-based computation of the transition probability kernel P(x, a, y).\n",
    "    Uses JAX's vmap to vectorize the scalar function over all (x, a, y) combinations.\n",
    "    \"\"\"\n",
    "    K, p = model\n",
    "    S = K + 1\n",
    "\n",
    "    def P(x, a, y):\n",
    "        \"\"\"\n",
    "        Scalar function to compute P(x, a, y) for a single (x, a, y) triple.\n",
    "        See the mathematical derivation above for the complete formula.\n",
    "        \"\"\"\n",
    "        d = x + a - y\n",
    "        # Test 0 <= x + a - y < x (first term)\n",
    "        valid_d = jnp.logical_and(0 <= d, d < x)\n",
    "        # Test y = a (second term)\n",
    "        y_eq_a = jnp.equal(y, a)\n",
    "        # Combine: 1{0 ≤ x + a - y < x} φ(x + a - y) + 1{y = a} F(x)\n",
    "        return valid_d * ϕ(p, d) + y_eq_a * F(p, x)\n",
    "\n",
    "    # Create all combinations of (x, a, y) indices\n",
    "    x_vals = jnp.arange(S)\n",
    "    a_vals = jnp.arange(S)  \n",
    "    y_vals = jnp.arange(S)\n",
    "    \n",
    "    # Use vmap to compute P(x,a,y) for all combinations\n",
    "    vmap_y = jax.vmap(P,      (None, None, 0))\n",
    "    vmap_a = jax.vmap(vmap_y, (None, 0, None))\n",
    "    vmap_x = jax.vmap(vmap_a, (0, None, None))\n",
    "    \n",
    "    return vmap_x(x_vals, a_vals, y_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624de8fc",
   "metadata": {},
   "source": [
    "## Correctness Verification\n",
    "\n",
    "Let's verify that all three methods produce identical results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c721d0c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T05:07:25.278276Z",
     "iopub.status.busy": "2025-10-07T05:07:25.278123Z",
     "iopub.status.idle": "2025-10-07T05:07:26.750581Z",
     "shell.execute_reply": "2025-10-07T05:07:26.750137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Correctness Check ===\n",
      "Vectorized P equals loops P: True\n",
      "Vmap P equals loops P: True\n",
      "\n",
      "All feasible probability sums equal 1: True\n",
      "Max deviation from 1 (feasible): 2.22e-16\n"
     ]
    }
   ],
   "source": [
    "# Compute results using all three methods\n",
    "loops_P = generate_kernel_loops(model)\n",
    "vectorized_P = generate_kernel_vectorized(model)\n",
    "vmap_P = generate_kernel_vmap(model)\n",
    "\n",
    "print(\"=== Correctness Check ===\")\n",
    "print(f\"Vectorized P equals loops P: {np.allclose(loops_P, vectorized_P)}\")\n",
    "print(f\"Vmap P equals loops P: {np.allclose(loops_P, vmap_P)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Verify that probabilities sum to 1 for each feasible (x, a) pair\n",
    "# A pair (x, a) is feasible if x + a <= K (capacity constraint)\n",
    "prob_sums = np.sum(loops_P, axis=2)\n",
    "feasible_mask = np.add.outer(np.arange(model.K + 1), np.arange(model.K + 1)) <= model.K\n",
    "feasible_sums = prob_sums[feasible_mask]\n",
    "print(f\"All feasible probability sums equal 1: {np.allclose(feasible_sums, 1.0)}\")\n",
    "print(f\"Max deviation from 1 (feasible): {np.max(np.abs(feasible_sums - 1.0)):.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d8be0a",
   "metadata": {},
   "source": [
    "## Performance Benchmarking\n",
    "\n",
    "Now let's compare the performance of all three approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af986411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T05:07:26.751923Z",
     "iopub.status.busy": "2025-10-07T05:07:26.751683Z",
     "iopub.status.idle": "2025-10-07T05:07:26.856254Z",
     "shell.execute_reply": "2025-10-07T05:07:26.855804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up JIT compilation...\n",
      "Warmup complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create JIT-compiled versions\n",
    "gen_kernel_vectorized_jit = jax.jit(generate_kernel_vectorized, static_argnums=(0,))\n",
    "gen_kernel_vmapped_jit = jax.jit(generate_kernel_vmap, static_argnums=(0,))\n",
    "\n",
    "# Warm up JIT compilation\n",
    "print(\"Warming up JIT compilation...\")\n",
    "_ = generate_kernel_loops(model)\n",
    "_ = gen_kernel_vectorized_jit(model)\n",
    "_ = gen_kernel_vmapped_jit(model)\n",
    "\n",
    "print(\"Warmup complete.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce52cb2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T05:07:26.857521Z",
     "iopub.status.busy": "2025-10-07T05:07:26.857397Z",
     "iopub.status.idle": "2025-10-07T05:07:28.775733Z",
     "shell.execute_reply": "2025-10-07T05:07:28.775390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running performance benchmarks (100 iterations each)...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 200/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 400/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 500/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 600/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 700/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 800/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 900/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1000/1000\n",
      "\n",
      "=== Performance Results ===\n",
      "Loops (Numba):  1710.3 ± 19.0 μs\n",
      "Vectorized:     96.4 ± 16.5 μs\n",
      "Vmap:           104.9 ± 18.0 μs\n",
      "\n",
      "=== Relative Performance ===\n",
      "Vectorized vs Loops: 17.7x faster\n",
      "Vmap vs Loops:       16.3x faster\n",
      "Vmap vs Vectorized:  0.9x slower\n"
     ]
    }
   ],
   "source": [
    "# Run performance benchmarks\n",
    "print(\"Running performance benchmarks (100 iterations each)...\")\n",
    "print()\n",
    "\n",
    "times_loops_jit = []\n",
    "times_vec_jit = []\n",
    "times_vmap_jit = []\n",
    "\n",
    "n_iterations = 1000\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"Progress: {i + 1}/{n_iterations}\")\n",
    "    \n",
    "    # Benchmark loops\n",
    "    start = time.perf_counter()\n",
    "    _ = generate_kernel_loops(model)\n",
    "    end = time.perf_counter()\n",
    "    times_loops_jit.append(end - start)\n",
    "\n",
    "    # Benchmark vectorized\n",
    "    start = time.perf_counter()\n",
    "    _ = gen_kernel_vectorized_jit(model).block_until_ready()\n",
    "    end = time.perf_counter()\n",
    "    times_vec_jit.append(end - start)\n",
    "    \n",
    "    # Benchmark vmap\n",
    "    start = time.perf_counter()\n",
    "    _ = gen_kernel_vmapped_jit(model).block_until_ready()\n",
    "    end = time.perf_counter()\n",
    "    times_vmap_jit.append(end - start)\n",
    "\n",
    "print(\"\\n=== Performance Results ===\")\n",
    "print(f\"Loops (Numba):  {np.mean(times_loops_jit)*1000000:.1f} ± {np.std(times_loops_jit)*1000000:.1f} μs\")\n",
    "print(f\"Vectorized:     {np.mean(times_vec_jit)*1000000:.1f} ± {np.std(times_vec_jit)*1000000:.1f} μs\")\n",
    "print(f\"Vmap:           {np.mean(times_vmap_jit)*1000000:.1f} ± {np.std(times_vmap_jit)*1000000:.1f} μs\")\n",
    "print()\n",
    "\n",
    "# Calculate speedups\n",
    "loops_mean = np.mean(times_loops_jit)\n",
    "vec_mean = np.mean(times_vec_jit) \n",
    "vmap_mean = np.mean(times_vmap_jit)\n",
    "\n",
    "print(\"=== Relative Performance ===\")\n",
    "print(f\"Vectorized vs Loops: {loops_mean / vec_mean:.1f}x {'faster' if vec_mean < loops_mean else 'slower'}\")\n",
    "print(f\"Vmap vs Loops:       {loops_mean / vmap_mean:.1f}x {'faster' if vmap_mean < loops_mean else 'slower'}\")\n",
    "print(f\"Vmap vs Vectorized:  {vec_mean / vmap_mean:.1f}x {'faster' if vmap_mean < vec_mean else 'slower'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012e6007",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "This notebook demonstrated three different approaches to computing transition probabilities in a stochastic inventory model:\n",
    "\n",
    "1. **Loop-based with Numba**: Traditional nested loops with JIT compilation\n",
    "2. **Vectorized JAX**: Fully vectorized operations using meshgrids\n",
    "3. **Vmap JAX**: Functional transformation of scalar operations\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "- All three methods produce identical results, confirming correctness\n",
    "- The JAX-based approaches are faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1e83c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
