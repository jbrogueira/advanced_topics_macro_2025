\input{../../preamble}

\title{Numerical Computing: Background}
\subtitle{Prepared for the Bank of Portugal Computational Economics Course}

\author{John Stachurski}


\date{October 2025}


\begin{document}

\begin{frame}
  \titlepage
\end{frame}



\begin{frame}
    \frametitle{Topics}

    \begin{itemize}
        \item Low level languages
        \vspace{0.5em}
        \item Interpreted code
        \vspace{0.5em}
        \item Array processing
        \vspace{0.5em}
        \item JIT compilation
    \end{itemize}

\end{frame}


\begin{frame}
    \frametitle{History: Setting the stage}

    Let's briefly discuss the evolution of scientific computing

    \vspace{0.5em}
    Let's recall some of the major paradigms and ideas:

    \vspace{0.5em}
    \begin{itemize}
        \item Languages and compilers
    \vspace{0.5em}
        \item Dynamic and static types
    \vspace{0.5em}
        \item Background on vectorization / JIT compilers
    \end{itemize}

\end{frame}
    


\begin{frame}
    \frametitle{Fortran / C  --- static types and AOT compilers}


    \Eg Suppose we want to compute the sequence
    %
    \begin{equation*}
        k_{t+1} = s k_t^\alpha + (1 - \delta) k_t
    \end{equation*}
    %
    from some given $k_0$ 

        \vspace{0.5em}
        \vspace{0.5em}
        \vspace{0.5em}

    Let's write a function in C that 
    %
    \begin{enumerate}
        \item implements the loop 
        \vspace{0.5em}
        \item returns the last $k_t$
    \end{enumerate}


\end{frame}


\begin{frame}[fragile]
    
    \begin{minted}{c}

int main() {
    double k = 0.2;
    double alpha = 0.4;
    double s = 0.3;
    double delta = 0.1;
    int i;
    int n = 1000;
    for (i = 0; i < n; i++) {
        k = s * pow(k, alpha) + (1 - delta) * k;
    }
    printf("k = %f\n", k);
}
    \end{minted}

\end{frame}



\begin{frame}[fragile]


    First we compile the whole program (ahead-of-time compilation):
    
    \vspace{0.5em}
    \begin{minted}{zsh}
❯❯ gcc solow.c -o out -lm
    \end{minted}



    \vspace{0.5em}
    \vspace{0.5em}
    \vspace{0.5em}
    Now we execute:

    \vspace{0.5em}
    \begin{minted}{zsh}
❯❯ ./out 
x = 6.240251
    \end{minted}

\end{frame}


\begin{frame}

    Pros

    \begin{itemize}
        \item fast arithmetic
        \item fast loops
    \end{itemize}


    \vspace{0.5em}

    Cons

    \begin{itemize}
        \item slow to write
        \item lack of portability
        \item hard to debug
        \item hard to parallelize
        \item low interactivity
    \end{itemize}

\end{frame}

\begin{frame}[fragile]


    For comparison, the same operation in Python:
    
    \begin{minted}{python}

α = 0.4
s = 0.3
δ = 0.1
n = 1_000
k = 0.2

for i in range(n-1):
    k = s * k**α + (1 - δ) * k

print(k)

    \end{minted}

\end{frame}


\begin{frame}
    
    Python is \brown{interpreted} rather than compiled

    \vspace{0.5em}
    \begin{itemize}
        \item code is executed statement by statement
    \vspace{0.5em}
        \item data types are queried on the fly
    \vspace{0.5em}
        \item arithmetic operations require method resolution
    \end{itemize}

\end{frame}

\begin{frame}

    Pros

    \begin{itemize}
        \item easy to write
        \item high portability
        \item immediate feedback --- high interactivity
        \item easy to debug
    \end{itemize}

    \vspace{0.5em}

    Cons

    \begin{itemize}
        \item slow
    \end{itemize}

\end{frame}


\begin{frame}
    
    So how can we get 

    \begin{center}
    good execution speeds \navy{and} high productivity / interactivity?
    \end{center}

\end{frame}

\begin{frame}
    \frametitle{MATLAB}

    ``MATLAB is Fortran for the 1990s!''

    \vspace{0.5em}
    \vspace{0.5em}

    \begin{figure}
       \centering
       \scalebox{.6}{\includegraphics[trim={2cm 8cm 6cm 3cm},clip]{matlab.pdf}}
    \end{figure}


\end{frame}



\begin{frame}[fragile]
    
    \begin{minted}{matlab}
        A = [2.0, -1.0
             5.0, -0.5];

        b = [0.5, 1.0]';

        x = inv(A) * b
    \end{minted}
    
\end{frame}



    


\begin{frame}
    \frametitle{Python + NumPy}

    Open source MATLAB-like array operations within Python

    \begin{figure}
       \begin{center} % l b r t
        \scalebox{.6}{\includegraphics[trim={2cm 8cm 6cm 3cm},clip]{numpy.pdf}}
       \end{center}
    \end{figure}

\end{frame}

\begin{frame}[fragile]

    \begin{minted}{python}
        import numpy 

        A = ((2.0, -1.0),
             (5.0, -0.5))

        b = (0.5, 1.0)

        A, b = np.array(A), np.array(b)

        x = np.inv(A) @ b
    \end{minted}

\end{frame}

\begin{frame}
    
    \begin{enumerate}
        \item Arrays defined with high-level commands 
        \vspace{0.5em}
        %
        \begin{itemize}
            \item (Python / NumPy API)
        \end{itemize}
        %
        \vspace{0.5em}
        \item Execution takes place in an efficient low-level environment
        \vspace{0.5em}
        %
        \begin{itemize}
            \item Efficient machine code (compiled C / Fortran)
        \end{itemize}
        %
        \vspace{0.5em}
        \item Results are returned to the high-level interface
    \end{enumerate}

\end{frame}



\begin{frame}
    
    Advantages of NumPy / MATLAB

    \vspace{0.5em}
    \begin{itemize}
        \item Operations are passed to specialized machine code 
        \vspace{0.5em}
        \item Type-checking is paid per array, not per array element
    \end{itemize}

    \vspace{0.5em}
    \vspace{0.5em}
    Disadvantages 

    \begin{itemize}
        \item Can be highly memory intensive (intermediate arrays)
        \vspace{0.5em}
        \item \underline{Fails} to specialize on array \brown{shapes}
        \vspace{0.5em}
        \item Limited --- how would you accelerate the Solow code using NumPy?
    \end{itemize}

\end{frame}







\begin{frame}[fragile]
    \frametitle{Julia --- rise of the JIT compilers}

    Can do MATLAB / NumPy style vectorized operations

    \begin{minted}{julia}
A = [2.0  -1.0
     5.0  -0.5]

b = [0.5  1.0]'

x = inv(A) * b
    \end{minted}
    

    \vspace{0.5em}
    \vspace{0.5em}
    But also has fast loops via an efficient JIT compiler

\end{frame}


\begin{frame}
    
    \Eg Suppose, again, that we want to compute 
    %
    \begin{equation*}
        k_{t+1} = s k_t^\alpha + (1 - \delta) k_t
    \end{equation*}
    %
    from some given $k_0$ 


    \vspace{0.5em}
    \vspace{0.5em}
    \vspace{0.5em}
    \vspace{0.5em}
    \begin{itemize}
        \item Iterative, not easily vectorized
    \end{itemize}

\end{frame}


\begin{frame}[fragile]
    
    \begin{minted}{julia}

function solow(k0, α=0.4, δ=0.1, n=1_000)
    k = k0
    for i in 1:(n-1)
        k = s * k^α + (1 - δ) * k
    end
    return k
end

solow(0.2)  # JIT-compiled at first call
    \end{minted}

    \vspace{0.5em}
    \vspace{0.5em}
    \vspace{0.5em}
    \vspace{0.5em}

    Julia accelerates \texttt{solow} at runtime via a JIT compiler

\end{frame}


\begin{frame}
    
    Pros:

    \begin{itemize}
        \item fast execution --- assuming correct type inference
        \vspace{0.2em}
        \item dynamically typed\ldots (but compiler wants type stability)
        \vspace{0.2em}
        \item close to the maths
    \end{itemize}

        \vspace{0.2em}
        \vspace{0.2em}
        \vspace{0.2em}
        \vspace{0.2em}
        \vspace{0.2em}
        \vspace{0.2em}
    Cons:

    \begin{itemize}
        \item Everything compiled might not be optimal 
        \vspace{0.2em}
        \begin{itemize}
            \item debugging is more challenging
            \vspace{0.2em}
            \item slow first runs
            \vspace{0.2em}
        \end{itemize}
        \vspace{0.2em}
        \item Repeated breaking changes and package instability
        \vspace{0.2em}
        \item Parallelization not well automated
    \end{itemize}

\end{frame}

\begin{frame}[fragile]
    \frametitle{Python + Numba --- same architecture, same speed}
    
    \begin{minted}{python}
from numba import jit

@jit(nopython=True)
def solow(k0, α=0.4, δ=0.1, n=1_000):
    k = k0
    for i in range(n-1):
        k = s * k**α + (1 - δ) * k
    return k

solow(0.2)
    \end{minted}


    Runs at same speed as Julia / C / Fortran

\end{frame}



\end{document}
